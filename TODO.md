# TODO - Crawler MCP Improvements

## Investigation Tasks

- [ ] Investigate register_github_pr_tools
- [ ] Investigate OPTIMIZED_CRAWLER environment variables
- [ ] Investigate hash placeholders filter
- [ ] Investigate RAG settings applied to crawler config
- [ ] Remove the filter from crawling a repo, we want all the files in the repo embedded
- [ ] Research best way to handle crawling/embedding repos
- [ ] Investigate our reranker, and if theres custom algorithms
- [ ] Investigate our chunking strategy, and research alternatives
- [ ] Research methods to keep our information up to date
- [ ] Research crawl dispatcher - https://docs.crawl4ai.com/advanced/crawl-dispatcher/
- [ ] Research undetected browser - https://docs.crawl4ai.com/advanced/undetected-browser/
- [ ] Research multi url crawling - https://docs.crawl4ai.com/advanced/multi-url-crawling/
- [ ] Research pdf parsing - https://docs.crawl4ai.com/advanced/pdf-parsing/
- [ ] Investigate our deduplication code

## Notes

This TODO list tracks improvements and investigations for the crawler MCP server functionality.
